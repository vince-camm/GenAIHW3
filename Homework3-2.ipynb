{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Vincent Cammisa GENAI Assignment 3"
      ],
      "metadata": {
        "id": "5gRaYkz9zz83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Load and Preprocess the SVHN Dataset\n",
        "\n",
        "- Use the commands provided above to download and load the SVHN dataset.\n",
        "- Preprocess the images (normalize and reshape).\n",
        "- Display the shape of the training and test datasets."
      ],
      "metadata": {
        "id": "IgOlfimIxPqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYHd5KgxV8e",
        "outputId": "19bb116e-4930-40ae-f434-9fa945d39448"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-16 00:59:01--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  3.11MB/s    in 68s     \n",
            "\n",
            "2024-10-16 01:00:09 (2.56 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2024-10-16 01:00:09--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  2.39MB/s    in 28s     \n",
            "\n",
            "2024-10-16 01:00:37 (2.20 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# Load data\n",
        "train_data = loadmat('train_32x32.mat')\n",
        "test_data = loadmat('test_32x32.mat')\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = np.transpose(train_data['X'], (3, 0, 1, 2)).astype('float32') / 255.0\n",
        "y_train = train_data['y'].flatten()\n",
        "x_test = np.transpose(test_data['X'], (3, 0, 1, 2)).astype('float32') / 255.0\n",
        "y_test = test_data['y'].flatten()\n",
        "\n",
        "# Display the shape of the datasets\n",
        "print(f'Training data shape: {x_train.shape}')\n",
        "print(f'Test data shape: {x_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcPRfkHvxdsY",
        "outputId": "c7944664-b2bf-4d77-c70c-1f8d27a0ef57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (73257, 32, 32, 3)\n",
            "Test data shape: (26032, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Build a Variational Autoencoder\n",
        "\n",
        "- Define the encoder and decoder architecture for the VAE.\n",
        "- Create the complete VAE model using the function: build_vae(latent_dim)\n",
        "- Ensure it can take a specified latent dimension."
      ],
      "metadata": {
        "id": "uJAIQX4_yvRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "0XuXmerjyuNv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 2\n",
        "EPOCHS = 5\n",
        "BETA = 500"
      ],
      "metadata": {
        "id": "0K3UXJVUy2WC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "jjhkYzEOy2g_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENCODER\n",
        "latent_dim = EMBEDDING_DIM\n",
        "encoder_input = layers.Input(shape=(32, 32, 3), name=\"encoder_input\") # Changed input shape to (32, 32, 3)\n",
        "x = layers.Conv2D(\n",
        "    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(encoder_input)\n",
        "x = layers.Conv2D(\n",
        "    64, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    128, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x) # Use the defined latent_dim\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "Z_E0Ge-Vy2p7",
        "outputId": "f033df85-f30a-44b2-c2cb-a6ab0e31099e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m896\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m18,496\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m73,856\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │          \u001b[38;5;34m4,098\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │          \u001b[38;5;34m4,098\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sampling (\u001b[38;5;33mSampling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,444\u001b[0m (396.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,444</span> (396.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,444\u001b[0m (396.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,444</span> (396.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DECODER\n",
        "\n",
        "decoder_input = layers.Input(shape=(EMBEDDING_DIM,), name=\"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "decoder_output = layers.Conv2D(\n",
        "    3,\n",
        "    (3, 3),\n",
        "    strides=1,\n",
        "    activation=\"sigmoid\",\n",
        "    padding=\"same\",\n",
        "    name=\"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "3N4i2K0QzFZn",
        "outputId": "f9c1fcf3-0a17-4fd5-87fc-c193bbfcf4ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │           \u001b[38;5;34m6,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m73,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_2 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m18,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_output (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │             \u001b[38;5;34m867\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m246,851\u001b[0m (964.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">246,851</span> (964.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m246,851\u001b[0m (964.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">246,851</span> (964.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z_mean, z_log_var, reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, reconstruction = self(data)\n",
        "            reconstruction_loss = tf.reduce_mean(BETA * losses.binary_crossentropy(data, reconstruction, axis=(1, 2, 3)))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "\n",
        "        z_mean, z_log_var, reconstruction = self(data)\n",
        "        reconstruction_loss = tf.reduce_mean(BETA * losses.binary_crossentropy(data, reconstruction, axis=(1, 2, 3)))\n",
        "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1))\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n",
        ""
      ],
      "metadata": {
        "id": "T5SsZlrjzO3a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vae(latent_dim):\n",
        "    vae = VAE(encoder, decoder)\n",
        "    return vae\n",
        "\n",
        "vae_model = build_vae(EMBEDDING_DIM)\n",
        "vae_model.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "c2sKrM4s1Fs1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Train the VAE with Different Latent Dimensions\n",
        "\n",
        "- Train the VAE with latent dimensions of 2, 5, and 10. Use the following for-loop in main:\n",
        "- Monitor the training process and evaluate the model's performance."
      ],
      "metadata": {
        "id": "h7wL0hbkzv6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dims = [2, 5, 10]\n",
        "for dim in latent_dims:\n",
        "    print(f'Training VAE with latent dimension: {dim}')\n",
        "    vae = build_vae(latent_dim=dim)\n",
        "    vae.compile(optimizer='adam', loss=losses.binary_crossentropy)\n",
        "    vae.fit(x_train, x_train, epochs=50, batch_size=128, validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT6fOdwazcgI",
        "outputId": "4ae88cd6-be09-427d-e4ce-c9416356f421"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VAE with latent dimension: 2\n",
            "Epoch 1/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - kl_loss: 1.4070 - reconstruction_loss: 333.4413 - total_loss: 334.8484 - val_kl_loss: 2.2818 - val_loss: 323.6547 - val_reconstruction_loss: 321.3729\n",
            "Epoch 2/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 2.5050 - reconstruction_loss: 321.4223 - total_loss: 323.9273 - val_kl_loss: 2.5512 - val_loss: 320.5588 - val_reconstruction_loss: 318.0076\n",
            "Epoch 3/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.6229 - reconstruction_loss: 319.9318 - total_loss: 322.5547 - val_kl_loss: 2.6484 - val_loss: 318.9148 - val_reconstruction_loss: 316.2663\n",
            "Epoch 4/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.7559 - reconstruction_loss: 318.7435 - total_loss: 321.4995 - val_kl_loss: 2.9338 - val_loss: 316.7190 - val_reconstruction_loss: 313.7852\n",
            "Epoch 5/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.8077 - reconstruction_loss: 318.2139 - total_loss: 321.0215 - val_kl_loss: 2.9351 - val_loss: 316.5798 - val_reconstruction_loss: 313.6447\n",
            "Epoch 6/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 2.8143 - reconstruction_loss: 318.2724 - total_loss: 321.0867 - val_kl_loss: 3.0661 - val_loss: 316.5453 - val_reconstruction_loss: 313.4792\n",
            "Epoch 7/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.8244 - reconstruction_loss: 318.1851 - total_loss: 321.0095 - val_kl_loss: 2.9743 - val_loss: 315.7657 - val_reconstruction_loss: 312.7914\n",
            "Epoch 8/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.8275 - reconstruction_loss: 318.0983 - total_loss: 320.9259 - val_kl_loss: 2.9459 - val_loss: 315.9502 - val_reconstruction_loss: 313.0042\n",
            "Epoch 9/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.8237 - reconstruction_loss: 318.0286 - total_loss: 320.8524 - val_kl_loss: 2.9373 - val_loss: 315.8153 - val_reconstruction_loss: 312.8781\n",
            "Epoch 10/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 2.8474 - reconstruction_loss: 318.0972 - total_loss: 320.9445 - val_kl_loss: 2.9890 - val_loss: 316.4788 - val_reconstruction_loss: 313.4897\n",
            "Epoch 11/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.8404 - reconstruction_loss: 318.2432 - total_loss: 321.0836 - val_kl_loss: 3.0109 - val_loss: 316.2094 - val_reconstruction_loss: 313.1985\n",
            "Epoch 12/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.8474 - reconstruction_loss: 318.1180 - total_loss: 320.9653 - val_kl_loss: 2.9712 - val_loss: 315.9119 - val_reconstruction_loss: 312.9408\n",
            "Epoch 13/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 2.8752 - reconstruction_loss: 317.7970 - total_loss: 320.6721 - val_kl_loss: 2.9994 - val_loss: 316.2827 - val_reconstruction_loss: 313.2833\n",
            "Epoch 14/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.8636 - reconstruction_loss: 318.0331 - total_loss: 320.8967 - val_kl_loss: 3.0160 - val_loss: 316.1313 - val_reconstruction_loss: 313.1153\n",
            "Epoch 15/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.8763 - reconstruction_loss: 318.0157 - total_loss: 320.8918 - val_kl_loss: 2.8991 - val_loss: 316.7863 - val_reconstruction_loss: 313.8871\n",
            "Epoch 16/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.8963 - reconstruction_loss: 317.8307 - total_loss: 320.7270 - val_kl_loss: 3.0425 - val_loss: 316.2340 - val_reconstruction_loss: 313.1915\n",
            "Epoch 17/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.9086 - reconstruction_loss: 317.9612 - total_loss: 320.8699 - val_kl_loss: 3.0332 - val_loss: 316.1783 - val_reconstruction_loss: 313.1451\n",
            "Epoch 18/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9198 - reconstruction_loss: 317.6113 - total_loss: 320.5312 - val_kl_loss: 2.9680 - val_loss: 316.1758 - val_reconstruction_loss: 313.2078\n",
            "Epoch 19/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 2.9071 - reconstruction_loss: 317.8528 - total_loss: 320.7598 - val_kl_loss: 3.0102 - val_loss: 316.2356 - val_reconstruction_loss: 313.2253\n",
            "Epoch 20/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.9335 - reconstruction_loss: 317.8336 - total_loss: 320.7671 - val_kl_loss: 2.8767 - val_loss: 316.0832 - val_reconstruction_loss: 313.2065\n",
            "Epoch 21/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.9347 - reconstruction_loss: 317.8043 - total_loss: 320.7389 - val_kl_loss: 3.1032 - val_loss: 316.1407 - val_reconstruction_loss: 313.0374\n",
            "Epoch 22/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9428 - reconstruction_loss: 317.8425 - total_loss: 320.7852 - val_kl_loss: 3.0133 - val_loss: 316.0019 - val_reconstruction_loss: 312.9885\n",
            "Epoch 23/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 2.9384 - reconstruction_loss: 317.9468 - total_loss: 320.8853 - val_kl_loss: 3.0974 - val_loss: 316.2888 - val_reconstruction_loss: 313.1914\n",
            "Epoch 24/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9552 - reconstruction_loss: 317.7534 - total_loss: 320.7086 - val_kl_loss: 3.0961 - val_loss: 316.0109 - val_reconstruction_loss: 312.9148\n",
            "Epoch 25/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 2.9541 - reconstruction_loss: 317.7526 - total_loss: 320.7068 - val_kl_loss: 3.1612 - val_loss: 316.2495 - val_reconstruction_loss: 313.0883\n",
            "Epoch 26/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9739 - reconstruction_loss: 317.7760 - total_loss: 320.7499 - val_kl_loss: 3.2495 - val_loss: 315.9660 - val_reconstruction_loss: 312.7165\n",
            "Epoch 27/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9775 - reconstruction_loss: 317.7746 - total_loss: 320.7522 - val_kl_loss: 3.1102 - val_loss: 316.1725 - val_reconstruction_loss: 313.0623\n",
            "Epoch 28/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9749 - reconstruction_loss: 317.5213 - total_loss: 320.4963 - val_kl_loss: 3.0810 - val_loss: 315.8399 - val_reconstruction_loss: 312.7589\n",
            "Epoch 29/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 2.9824 - reconstruction_loss: 317.4937 - total_loss: 320.4760 - val_kl_loss: 3.2690 - val_loss: 316.0883 - val_reconstruction_loss: 312.8193\n",
            "Epoch 30/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9921 - reconstruction_loss: 317.6978 - total_loss: 320.6900 - val_kl_loss: 3.0466 - val_loss: 316.5332 - val_reconstruction_loss: 313.4866\n",
            "Epoch 31/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 2.9803 - reconstruction_loss: 317.6429 - total_loss: 320.6231 - val_kl_loss: 3.0321 - val_loss: 315.6702 - val_reconstruction_loss: 312.6381\n",
            "Epoch 32/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0076 - reconstruction_loss: 317.5049 - total_loss: 320.5125 - val_kl_loss: 3.1319 - val_loss: 316.0730 - val_reconstruction_loss: 312.9411\n",
            "Epoch 33/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 2.9996 - reconstruction_loss: 317.6576 - total_loss: 320.6571 - val_kl_loss: 3.1447 - val_loss: 316.3280 - val_reconstruction_loss: 313.1833\n",
            "Epoch 34/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.0133 - reconstruction_loss: 317.7073 - total_loss: 320.7207 - val_kl_loss: 3.0969 - val_loss: 316.0486 - val_reconstruction_loss: 312.9516\n",
            "Epoch 35/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.0076 - reconstruction_loss: 317.7683 - total_loss: 320.7759 - val_kl_loss: 3.0956 - val_loss: 316.0069 - val_reconstruction_loss: 312.9113\n",
            "Epoch 36/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0042 - reconstruction_loss: 317.6992 - total_loss: 320.7033 - val_kl_loss: 3.2183 - val_loss: 316.1089 - val_reconstruction_loss: 312.8906\n",
            "Epoch 37/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0162 - reconstruction_loss: 317.5711 - total_loss: 320.5874 - val_kl_loss: 3.2413 - val_loss: 316.3791 - val_reconstruction_loss: 313.1378\n",
            "Epoch 38/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - kl_loss: 3.0003 - reconstruction_loss: 317.6715 - total_loss: 320.6717 - val_kl_loss: 3.1019 - val_loss: 315.9566 - val_reconstruction_loss: 312.8547\n",
            "Epoch 39/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.0164 - reconstruction_loss: 317.6192 - total_loss: 320.6356 - val_kl_loss: 3.1883 - val_loss: 315.8135 - val_reconstruction_loss: 312.6252\n",
            "Epoch 40/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - kl_loss: 3.0149 - reconstruction_loss: 317.7117 - total_loss: 320.7264 - val_kl_loss: 3.1322 - val_loss: 315.8282 - val_reconstruction_loss: 312.6959\n",
            "Epoch 41/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0173 - reconstruction_loss: 317.4296 - total_loss: 320.4470 - val_kl_loss: 3.1970 - val_loss: 315.7067 - val_reconstruction_loss: 312.5096\n",
            "Epoch 42/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.0209 - reconstruction_loss: 317.6671 - total_loss: 320.6880 - val_kl_loss: 3.1191 - val_loss: 316.0614 - val_reconstruction_loss: 312.9423\n",
            "Epoch 43/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - kl_loss: 3.0227 - reconstruction_loss: 317.6784 - total_loss: 320.7013 - val_kl_loss: 3.1823 - val_loss: 316.5213 - val_reconstruction_loss: 313.3391\n",
            "Epoch 44/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - kl_loss: 3.0359 - reconstruction_loss: 317.4384 - total_loss: 320.4742 - val_kl_loss: 3.0871 - val_loss: 315.9812 - val_reconstruction_loss: 312.8940\n",
            "Epoch 45/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0135 - reconstruction_loss: 317.7985 - total_loss: 320.8119 - val_kl_loss: 3.1358 - val_loss: 315.9939 - val_reconstruction_loss: 312.8581\n",
            "Epoch 46/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.0236 - reconstruction_loss: 317.8076 - total_loss: 320.8313 - val_kl_loss: 3.1639 - val_loss: 315.9581 - val_reconstruction_loss: 312.7943\n",
            "Epoch 47/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0290 - reconstruction_loss: 317.4904 - total_loss: 320.5194 - val_kl_loss: 3.2476 - val_loss: 315.7141 - val_reconstruction_loss: 312.4664\n",
            "Epoch 48/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.0422 - reconstruction_loss: 317.6688 - total_loss: 320.7111 - val_kl_loss: 3.1309 - val_loss: 315.9345 - val_reconstruction_loss: 312.8036\n",
            "Epoch 49/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0443 - reconstruction_loss: 317.7578 - total_loss: 320.8022 - val_kl_loss: 3.1688 - val_loss: 316.2364 - val_reconstruction_loss: 313.0676\n",
            "Epoch 50/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0502 - reconstruction_loss: 317.5463 - total_loss: 320.5964 - val_kl_loss: 3.1355 - val_loss: 316.0918 - val_reconstruction_loss: 312.9563\n",
            "Training VAE with latent dimension: 5\n",
            "Epoch 1/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - kl_loss: 3.0406 - reconstruction_loss: 317.4396 - total_loss: 320.4802 - val_kl_loss: 3.1761 - val_loss: 316.1290 - val_reconstruction_loss: 312.9529\n",
            "Epoch 2/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - kl_loss: 3.0616 - reconstruction_loss: 317.3679 - total_loss: 320.4295 - val_kl_loss: 3.1745 - val_loss: 315.7946 - val_reconstruction_loss: 312.6201\n",
            "Epoch 3/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.0581 - reconstruction_loss: 317.4411 - total_loss: 320.4993 - val_kl_loss: 3.1146 - val_loss: 316.2726 - val_reconstruction_loss: 313.1581\n",
            "Epoch 4/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.0581 - reconstruction_loss: 317.3967 - total_loss: 320.4550 - val_kl_loss: 2.9981 - val_loss: 316.3480 - val_reconstruction_loss: 313.3498\n",
            "Epoch 5/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0530 - reconstruction_loss: 317.5431 - total_loss: 320.5963 - val_kl_loss: 3.1245 - val_loss: 315.7708 - val_reconstruction_loss: 312.6464\n",
            "Epoch 6/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0576 - reconstruction_loss: 317.5750 - total_loss: 320.6325 - val_kl_loss: 3.0372 - val_loss: 315.9057 - val_reconstruction_loss: 312.8684\n",
            "Epoch 7/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - kl_loss: 3.0720 - reconstruction_loss: 317.6358 - total_loss: 320.7078 - val_kl_loss: 3.1174 - val_loss: 316.2406 - val_reconstruction_loss: 313.1233\n",
            "Epoch 8/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0550 - reconstruction_loss: 317.3966 - total_loss: 320.4517 - val_kl_loss: 3.0555 - val_loss: 315.9317 - val_reconstruction_loss: 312.8762\n",
            "Epoch 9/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - kl_loss: 3.0787 - reconstruction_loss: 317.4005 - total_loss: 320.4792 - val_kl_loss: 3.1600 - val_loss: 316.1306 - val_reconstruction_loss: 312.9706\n",
            "Epoch 10/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0723 - reconstruction_loss: 317.2616 - total_loss: 320.3340 - val_kl_loss: 3.1434 - val_loss: 316.1739 - val_reconstruction_loss: 313.0305\n",
            "Epoch 11/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.0620 - reconstruction_loss: 317.3714 - total_loss: 320.4335 - val_kl_loss: 3.1919 - val_loss: 315.8712 - val_reconstruction_loss: 312.6793\n",
            "Epoch 12/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0623 - reconstruction_loss: 317.5656 - total_loss: 320.6280 - val_kl_loss: 3.2401 - val_loss: 315.8351 - val_reconstruction_loss: 312.5949\n",
            "Epoch 13/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0820 - reconstruction_loss: 317.4036 - total_loss: 320.4856 - val_kl_loss: 3.1255 - val_loss: 316.1623 - val_reconstruction_loss: 313.0368\n",
            "Epoch 14/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.0746 - reconstruction_loss: 317.5501 - total_loss: 320.6247 - val_kl_loss: 3.0966 - val_loss: 315.9698 - val_reconstruction_loss: 312.8732\n",
            "Epoch 15/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0714 - reconstruction_loss: 317.7372 - total_loss: 320.8085 - val_kl_loss: 3.1783 - val_loss: 316.0345 - val_reconstruction_loss: 312.8563\n",
            "Epoch 16/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.0939 - reconstruction_loss: 317.3292 - total_loss: 320.4231 - val_kl_loss: 3.2555 - val_loss: 316.0397 - val_reconstruction_loss: 312.7842\n",
            "Epoch 17/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.0877 - reconstruction_loss: 317.3489 - total_loss: 320.4366 - val_kl_loss: 3.1553 - val_loss: 315.9286 - val_reconstruction_loss: 312.7733\n",
            "Epoch 18/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0769 - reconstruction_loss: 317.6001 - total_loss: 320.6772 - val_kl_loss: 3.2483 - val_loss: 316.1991 - val_reconstruction_loss: 312.9508\n",
            "Epoch 19/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0750 - reconstruction_loss: 317.5438 - total_loss: 320.6188 - val_kl_loss: 3.2182 - val_loss: 315.6709 - val_reconstruction_loss: 312.4527\n",
            "Epoch 20/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0817 - reconstruction_loss: 317.3282 - total_loss: 320.4099 - val_kl_loss: 3.1874 - val_loss: 315.9322 - val_reconstruction_loss: 312.7448\n",
            "Epoch 21/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1012 - reconstruction_loss: 317.3975 - total_loss: 320.4987 - val_kl_loss: 3.2505 - val_loss: 316.0007 - val_reconstruction_loss: 312.7502\n",
            "Epoch 22/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.0996 - reconstruction_loss: 317.4474 - total_loss: 320.5471 - val_kl_loss: 3.1705 - val_loss: 316.3069 - val_reconstruction_loss: 313.1364\n",
            "Epoch 23/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1062 - reconstruction_loss: 317.4245 - total_loss: 320.5306 - val_kl_loss: 3.2067 - val_loss: 316.1204 - val_reconstruction_loss: 312.9137\n",
            "Epoch 24/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.0892 - reconstruction_loss: 317.3733 - total_loss: 320.4626 - val_kl_loss: 3.1779 - val_loss: 316.0133 - val_reconstruction_loss: 312.8355\n",
            "Epoch 25/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.1069 - reconstruction_loss: 317.4325 - total_loss: 320.5394 - val_kl_loss: 3.1144 - val_loss: 316.0566 - val_reconstruction_loss: 312.9422\n",
            "Epoch 26/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1014 - reconstruction_loss: 317.2930 - total_loss: 320.3943 - val_kl_loss: 3.1148 - val_loss: 315.8533 - val_reconstruction_loss: 312.7385\n",
            "Epoch 27/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1104 - reconstruction_loss: 317.3113 - total_loss: 320.4217 - val_kl_loss: 3.2945 - val_loss: 315.7315 - val_reconstruction_loss: 312.4370\n",
            "Epoch 28/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1177 - reconstruction_loss: 317.3414 - total_loss: 320.4590 - val_kl_loss: 3.1875 - val_loss: 315.7839 - val_reconstruction_loss: 312.5964\n",
            "Epoch 29/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.1232 - reconstruction_loss: 317.3780 - total_loss: 320.5013 - val_kl_loss: 3.2893 - val_loss: 315.5145 - val_reconstruction_loss: 312.2251\n",
            "Epoch 30/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1132 - reconstruction_loss: 317.3503 - total_loss: 320.4636 - val_kl_loss: 3.2499 - val_loss: 315.9884 - val_reconstruction_loss: 312.7385\n",
            "Epoch 31/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1089 - reconstruction_loss: 317.2895 - total_loss: 320.3984 - val_kl_loss: 3.2273 - val_loss: 315.9068 - val_reconstruction_loss: 312.6795\n",
            "Epoch 32/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.1302 - reconstruction_loss: 317.3866 - total_loss: 320.5168 - val_kl_loss: 3.1938 - val_loss: 316.3997 - val_reconstruction_loss: 313.2059\n",
            "Epoch 33/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1099 - reconstruction_loss: 317.4994 - total_loss: 320.6093 - val_kl_loss: 3.1832 - val_loss: 315.8019 - val_reconstruction_loss: 312.6187\n",
            "Epoch 34/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1200 - reconstruction_loss: 317.3989 - total_loss: 320.5188 - val_kl_loss: 3.2034 - val_loss: 316.1462 - val_reconstruction_loss: 312.9428\n",
            "Epoch 35/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.1187 - reconstruction_loss: 317.1736 - total_loss: 320.2923 - val_kl_loss: 3.2662 - val_loss: 315.9617 - val_reconstruction_loss: 312.6956\n",
            "Epoch 36/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1221 - reconstruction_loss: 317.1638 - total_loss: 320.2858 - val_kl_loss: 3.2356 - val_loss: 315.5221 - val_reconstruction_loss: 312.2866\n",
            "Epoch 37/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1099 - reconstruction_loss: 317.4733 - total_loss: 320.5832 - val_kl_loss: 3.2241 - val_loss: 315.9886 - val_reconstruction_loss: 312.7645\n",
            "Epoch 38/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1336 - reconstruction_loss: 317.4250 - total_loss: 320.5587 - val_kl_loss: 3.2198 - val_loss: 316.1053 - val_reconstruction_loss: 312.8855\n",
            "Epoch 39/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - kl_loss: 3.1331 - reconstruction_loss: 317.5603 - total_loss: 320.6933 - val_kl_loss: 3.0784 - val_loss: 315.9421 - val_reconstruction_loss: 312.8637\n",
            "Epoch 40/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - kl_loss: 3.1107 - reconstruction_loss: 317.2825 - total_loss: 320.3932 - val_kl_loss: 3.2435 - val_loss: 316.1343 - val_reconstruction_loss: 312.8908\n",
            "Epoch 41/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - kl_loss: 3.1454 - reconstruction_loss: 317.3333 - total_loss: 320.4789 - val_kl_loss: 3.2353 - val_loss: 316.0333 - val_reconstruction_loss: 312.7980\n",
            "Epoch 42/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - kl_loss: 3.1285 - reconstruction_loss: 317.3542 - total_loss: 320.4826 - val_kl_loss: 3.2970 - val_loss: 316.0005 - val_reconstruction_loss: 312.7034\n",
            "Epoch 43/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1386 - reconstruction_loss: 317.3046 - total_loss: 320.4431 - val_kl_loss: 3.2027 - val_loss: 316.0085 - val_reconstruction_loss: 312.8059\n",
            "Epoch 44/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1190 - reconstruction_loss: 317.2295 - total_loss: 320.3484 - val_kl_loss: 3.1747 - val_loss: 316.2581 - val_reconstruction_loss: 313.0835\n",
            "Epoch 45/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1457 - reconstruction_loss: 317.4274 - total_loss: 320.5731 - val_kl_loss: 3.2713 - val_loss: 315.7684 - val_reconstruction_loss: 312.4970\n",
            "Epoch 46/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - kl_loss: 3.1310 - reconstruction_loss: 317.4264 - total_loss: 320.5575 - val_kl_loss: 3.2772 - val_loss: 315.9643 - val_reconstruction_loss: 312.6871\n",
            "Epoch 47/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1493 - reconstruction_loss: 317.3842 - total_loss: 320.5335 - val_kl_loss: 3.2172 - val_loss: 316.0575 - val_reconstruction_loss: 312.8402\n",
            "Epoch 48/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1514 - reconstruction_loss: 317.2949 - total_loss: 320.4464 - val_kl_loss: 3.2985 - val_loss: 316.0414 - val_reconstruction_loss: 312.7429\n",
            "Epoch 49/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1473 - reconstruction_loss: 317.2021 - total_loss: 320.3494 - val_kl_loss: 3.2449 - val_loss: 315.9844 - val_reconstruction_loss: 312.7395\n",
            "Epoch 50/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.1366 - reconstruction_loss: 317.4058 - total_loss: 320.5424 - val_kl_loss: 3.2068 - val_loss: 315.6355 - val_reconstruction_loss: 312.4287\n",
            "Training VAE with latent dimension: 10\n",
            "Epoch 1/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - kl_loss: 3.1382 - reconstruction_loss: 317.3167 - total_loss: 320.4551 - val_kl_loss: 3.2179 - val_loss: 315.9713 - val_reconstruction_loss: 312.7534\n",
            "Epoch 2/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1441 - reconstruction_loss: 317.4335 - total_loss: 320.5776 - val_kl_loss: 3.1999 - val_loss: 315.6075 - val_reconstruction_loss: 312.4076\n",
            "Epoch 3/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1519 - reconstruction_loss: 317.1619 - total_loss: 320.3138 - val_kl_loss: 3.1911 - val_loss: 316.5501 - val_reconstruction_loss: 313.3591\n",
            "Epoch 4/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.1435 - reconstruction_loss: 317.1436 - total_loss: 320.2871 - val_kl_loss: 3.2584 - val_loss: 316.1541 - val_reconstruction_loss: 312.8957\n",
            "Epoch 5/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1494 - reconstruction_loss: 317.3784 - total_loss: 320.5277 - val_kl_loss: 3.2119 - val_loss: 315.9272 - val_reconstruction_loss: 312.7153\n",
            "Epoch 6/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1611 - reconstruction_loss: 317.5072 - total_loss: 320.6683 - val_kl_loss: 3.2448 - val_loss: 316.1331 - val_reconstruction_loss: 312.8883\n",
            "Epoch 7/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1423 - reconstruction_loss: 317.3164 - total_loss: 320.4587 - val_kl_loss: 3.2232 - val_loss: 315.8771 - val_reconstruction_loss: 312.6540\n",
            "Epoch 8/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1456 - reconstruction_loss: 317.4226 - total_loss: 320.5681 - val_kl_loss: 3.2442 - val_loss: 315.5642 - val_reconstruction_loss: 312.3200\n",
            "Epoch 9/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1562 - reconstruction_loss: 317.3439 - total_loss: 320.5000 - val_kl_loss: 3.3134 - val_loss: 315.8515 - val_reconstruction_loss: 312.5381\n",
            "Epoch 10/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1574 - reconstruction_loss: 317.2437 - total_loss: 320.4012 - val_kl_loss: 3.3143 - val_loss: 315.8889 - val_reconstruction_loss: 312.5746\n",
            "Epoch 11/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - kl_loss: 3.1640 - reconstruction_loss: 317.2800 - total_loss: 320.4440 - val_kl_loss: 3.2819 - val_loss: 315.6403 - val_reconstruction_loss: 312.3583\n",
            "Epoch 12/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1676 - reconstruction_loss: 317.2849 - total_loss: 320.4525 - val_kl_loss: 3.1560 - val_loss: 315.7623 - val_reconstruction_loss: 312.6063\n",
            "Epoch 13/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1596 - reconstruction_loss: 317.1447 - total_loss: 320.3043 - val_kl_loss: 3.1813 - val_loss: 316.5718 - val_reconstruction_loss: 313.3905\n",
            "Epoch 14/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.1658 - reconstruction_loss: 317.1079 - total_loss: 320.2736 - val_kl_loss: 3.2549 - val_loss: 315.7137 - val_reconstruction_loss: 312.4588\n",
            "Epoch 15/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1625 - reconstruction_loss: 317.2818 - total_loss: 320.4443 - val_kl_loss: 3.1688 - val_loss: 316.0290 - val_reconstruction_loss: 312.8602\n",
            "Epoch 16/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1575 - reconstruction_loss: 317.3173 - total_loss: 320.4748 - val_kl_loss: 3.1972 - val_loss: 315.6638 - val_reconstruction_loss: 312.4665\n",
            "Epoch 17/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1743 - reconstruction_loss: 317.1754 - total_loss: 320.3497 - val_kl_loss: 3.0534 - val_loss: 315.6925 - val_reconstruction_loss: 312.6390\n",
            "Epoch 18/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1641 - reconstruction_loss: 317.1822 - total_loss: 320.3464 - val_kl_loss: 3.2143 - val_loss: 316.4767 - val_reconstruction_loss: 313.2624\n",
            "Epoch 19/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - kl_loss: 3.1698 - reconstruction_loss: 317.2993 - total_loss: 320.4691 - val_kl_loss: 3.2322 - val_loss: 315.9113 - val_reconstruction_loss: 312.6790\n",
            "Epoch 20/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1838 - reconstruction_loss: 317.2382 - total_loss: 320.4220 - val_kl_loss: 3.2060 - val_loss: 315.8559 - val_reconstruction_loss: 312.6499\n",
            "Epoch 21/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1661 - reconstruction_loss: 317.2147 - total_loss: 320.3808 - val_kl_loss: 3.2481 - val_loss: 316.1050 - val_reconstruction_loss: 312.8569\n",
            "Epoch 22/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - kl_loss: 3.1733 - reconstruction_loss: 317.2524 - total_loss: 320.4257 - val_kl_loss: 3.2754 - val_loss: 316.3055 - val_reconstruction_loss: 313.0302\n",
            "Epoch 23/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - kl_loss: 3.1801 - reconstruction_loss: 317.3002 - total_loss: 320.4802 - val_kl_loss: 3.3090 - val_loss: 316.0413 - val_reconstruction_loss: 312.7324\n",
            "Epoch 24/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1815 - reconstruction_loss: 317.2837 - total_loss: 320.4652 - val_kl_loss: 3.1936 - val_loss: 315.7328 - val_reconstruction_loss: 312.5392\n",
            "Epoch 25/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1780 - reconstruction_loss: 317.1371 - total_loss: 320.3151 - val_kl_loss: 3.1686 - val_loss: 315.9821 - val_reconstruction_loss: 312.8135\n",
            "Epoch 26/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1798 - reconstruction_loss: 317.3091 - total_loss: 320.4889 - val_kl_loss: 3.2593 - val_loss: 316.0029 - val_reconstruction_loss: 312.7436\n",
            "Epoch 27/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1760 - reconstruction_loss: 317.1303 - total_loss: 320.3062 - val_kl_loss: 3.2483 - val_loss: 316.1696 - val_reconstruction_loss: 312.9213\n",
            "Epoch 28/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1839 - reconstruction_loss: 317.0635 - total_loss: 320.2474 - val_kl_loss: 3.2211 - val_loss: 315.7865 - val_reconstruction_loss: 312.5653\n",
            "Epoch 29/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1794 - reconstruction_loss: 317.2545 - total_loss: 320.4340 - val_kl_loss: 3.2780 - val_loss: 315.7524 - val_reconstruction_loss: 312.4744\n",
            "Epoch 30/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1755 - reconstruction_loss: 317.2631 - total_loss: 320.4385 - val_kl_loss: 3.2496 - val_loss: 315.5643 - val_reconstruction_loss: 312.3147\n",
            "Epoch 31/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1790 - reconstruction_loss: 317.0975 - total_loss: 320.2764 - val_kl_loss: 3.2385 - val_loss: 315.8637 - val_reconstruction_loss: 312.6252\n",
            "Epoch 32/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1983 - reconstruction_loss: 317.0113 - total_loss: 320.2096 - val_kl_loss: 3.2817 - val_loss: 316.3335 - val_reconstruction_loss: 313.0518\n",
            "Epoch 33/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1782 - reconstruction_loss: 317.3513 - total_loss: 320.5294 - val_kl_loss: 3.2566 - val_loss: 315.7585 - val_reconstruction_loss: 312.5020\n",
            "Epoch 34/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1823 - reconstruction_loss: 317.2522 - total_loss: 320.4344 - val_kl_loss: 3.3616 - val_loss: 316.1269 - val_reconstruction_loss: 312.7653\n",
            "Epoch 35/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1999 - reconstruction_loss: 317.1387 - total_loss: 320.3387 - val_kl_loss: 3.1299 - val_loss: 316.1083 - val_reconstruction_loss: 312.9785\n",
            "Epoch 36/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1815 - reconstruction_loss: 317.0905 - total_loss: 320.2722 - val_kl_loss: 3.2025 - val_loss: 315.7664 - val_reconstruction_loss: 312.5639\n",
            "Epoch 37/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1993 - reconstruction_loss: 317.2502 - total_loss: 320.4496 - val_kl_loss: 3.3183 - val_loss: 315.8106 - val_reconstruction_loss: 312.4923\n",
            "Epoch 38/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1931 - reconstruction_loss: 317.2379 - total_loss: 320.4309 - val_kl_loss: 3.2643 - val_loss: 315.9622 - val_reconstruction_loss: 312.6979\n",
            "Epoch 39/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - kl_loss: 3.2005 - reconstruction_loss: 317.0795 - total_loss: 320.2800 - val_kl_loss: 3.1998 - val_loss: 315.9131 - val_reconstruction_loss: 312.7133\n",
            "Epoch 40/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - kl_loss: 3.1906 - reconstruction_loss: 317.1476 - total_loss: 320.3382 - val_kl_loss: 3.2847 - val_loss: 315.7023 - val_reconstruction_loss: 312.4175\n",
            "Epoch 41/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.2025 - reconstruction_loss: 317.1841 - total_loss: 320.3867 - val_kl_loss: 3.2565 - val_loss: 315.7819 - val_reconstruction_loss: 312.5254\n",
            "Epoch 42/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.1923 - reconstruction_loss: 317.2788 - total_loss: 320.4710 - val_kl_loss: 3.3006 - val_loss: 315.8019 - val_reconstruction_loss: 312.5013\n",
            "Epoch 43/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1941 - reconstruction_loss: 317.1452 - total_loss: 320.3393 - val_kl_loss: 3.1672 - val_loss: 315.9947 - val_reconstruction_loss: 312.8275\n",
            "Epoch 44/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1987 - reconstruction_loss: 317.0807 - total_loss: 320.2794 - val_kl_loss: 3.2556 - val_loss: 316.0115 - val_reconstruction_loss: 312.7559\n",
            "Epoch 45/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1971 - reconstruction_loss: 317.1545 - total_loss: 320.3517 - val_kl_loss: 3.2896 - val_loss: 316.2478 - val_reconstruction_loss: 312.9583\n",
            "Epoch 46/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - kl_loss: 3.2038 - reconstruction_loss: 317.1424 - total_loss: 320.3461 - val_kl_loss: 3.3484 - val_loss: 315.9226 - val_reconstruction_loss: 312.5742\n",
            "Epoch 47/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - kl_loss: 3.2207 - reconstruction_loss: 316.8856 - total_loss: 320.1062 - val_kl_loss: 3.2374 - val_loss: 315.8389 - val_reconstruction_loss: 312.6015\n",
            "Epoch 48/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.1876 - reconstruction_loss: 317.1643 - total_loss: 320.3520 - val_kl_loss: 3.2105 - val_loss: 316.1493 - val_reconstruction_loss: 312.9388\n",
            "Epoch 49/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - kl_loss: 3.1870 - reconstruction_loss: 317.1672 - total_loss: 320.3541 - val_kl_loss: 3.2721 - val_loss: 315.4978 - val_reconstruction_loss: 312.2257\n",
            "Epoch 50/50\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 3.2200 - reconstruction_loss: 316.8958 - total_loss: 320.1158 - val_kl_loss: 3.3186 - val_loss: 315.5646 - val_reconstruction_loss: 312.2460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have a low kl_loss which is good\n",
        "- we also have a high reconstruction loss and consideering how fast our model trained id like to test outside experiments with higher epochs\n",
        "- our total and validation loss are also high but close which displays good generalization, also will rerun with double the epochs maybe"
      ],
      "metadata": {
        "id": "L2NzuTgKHScb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create visualizations of original and reconstructed images for the largest latent dimension."
      ],
      "metadata": {
        "id": "hsDsC7UsH10h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = 5000\n",
        "images = x_test[:predicts]\n",
        "labels = y_test[:predicts]\n",
        "z_mean, z_log_var, reconstructions = vae.predict(images)\n",
        "\n",
        "print(\"Examples of Original Images\")\n",
        "display(images)\n",
        "print(\"Reconstructed Images\")\n",
        "display(reconstructions)\n",
        "\n",
        "z_mean, z_var, z = encoder.predict(images)\n",
        "print(z[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lvNAXWmgH0h7",
        "outputId": "89c43305-58a6-4c10-a162-e4d91073384c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "Examples of Original Images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[0.14901961, 0.40392157, 0.23529412],\n",
              "         [0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.24313726],\n",
              "         ...,\n",
              "         [0.16078432, 0.4       , 0.23921569],\n",
              "         [0.16470589, 0.40392157, 0.24313726],\n",
              "         [0.15294118, 0.38039216, 0.22352941]],\n",
              "\n",
              "        [[0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.24313726],\n",
              "         ...,\n",
              "         [0.16078432, 0.4       , 0.23921569],\n",
              "         [0.16862746, 0.39607844, 0.24705882],\n",
              "         [0.15294118, 0.38039216, 0.22352941]],\n",
              "\n",
              "        [[0.14901961, 0.4117647 , 0.24313726],\n",
              "         [0.14509805, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.41568628, 0.24705882],\n",
              "         ...,\n",
              "         [0.16862746, 0.39607844, 0.24705882],\n",
              "         [0.16862746, 0.39215687, 0.2509804 ],\n",
              "         [0.15294118, 0.38039216, 0.23137255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20392157, 0.46666667, 0.30588236],\n",
              "         [0.20784314, 0.47058824, 0.30980393],\n",
              "         [0.2       , 0.4627451 , 0.3019608 ],\n",
              "         ...,\n",
              "         [0.17254902, 0.4627451 , 0.27058825],\n",
              "         [0.17254902, 0.45882353, 0.2784314 ],\n",
              "         [0.16078432, 0.44705883, 0.27058825]],\n",
              "\n",
              "        [[0.19607843, 0.45882353, 0.29803923],\n",
              "         [0.2       , 0.4627451 , 0.3019608 ],\n",
              "         [0.19215687, 0.45490196, 0.29411766],\n",
              "         ...,\n",
              "         [0.17254902, 0.45882353, 0.2784314 ],\n",
              "         [0.1764706 , 0.45490196, 0.28235295],\n",
              "         [0.16470589, 0.44313726, 0.27058825]],\n",
              "\n",
              "        [[0.1882353 , 0.4509804 , 0.2901961 ],\n",
              "         [0.1882353 , 0.4509804 , 0.2901961 ],\n",
              "         [0.18039216, 0.44313726, 0.28235295],\n",
              "         ...,\n",
              "         [0.16862746, 0.45490196, 0.2784314 ],\n",
              "         [0.17254902, 0.4509804 , 0.2784314 ],\n",
              "         [0.16470589, 0.44313726, 0.2784314 ]]],\n",
              "\n",
              "\n",
              "       [[[0.5058824 , 0.5568628 , 0.6       ],\n",
              "         [0.49803922, 0.56078434, 0.59607846],\n",
              "         [0.49019608, 0.56078434, 0.5921569 ],\n",
              "         ...,\n",
              "         [0.4745098 , 0.52156866, 0.6       ],\n",
              "         [0.48235294, 0.5254902 , 0.6117647 ],\n",
              "         [0.48235294, 0.5294118 , 0.6156863 ]],\n",
              "\n",
              "        [[0.5254902 , 0.5882353 , 0.627451  ],\n",
              "         [0.52156866, 0.58431375, 0.61960787],\n",
              "         [0.5176471 , 0.58431375, 0.6156863 ],\n",
              "         ...,\n",
              "         [0.49803922, 0.5411765 , 0.6156863 ],\n",
              "         [0.49411765, 0.5372549 , 0.6156863 ],\n",
              "         [0.49019608, 0.5372549 , 0.61960787]],\n",
              "\n",
              "        [[0.5529412 , 0.61960787, 0.65882355],\n",
              "         [0.54901963, 0.6156863 , 0.6509804 ],\n",
              "         [0.54901963, 0.6156863 , 0.64705884],\n",
              "         ...,\n",
              "         [0.5294118 , 0.5764706 , 0.6392157 ],\n",
              "         [0.5176471 , 0.56078434, 0.6313726 ],\n",
              "         [0.50980395, 0.5529412 , 0.627451  ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.5764706 , 0.6313726 , 0.68235296],\n",
              "         [0.5568628 , 0.6117647 , 0.6627451 ],\n",
              "         [0.53333336, 0.5921569 , 0.6392157 ],\n",
              "         ...,\n",
              "         [0.3647059 , 0.38039216, 0.49411765],\n",
              "         [0.3764706 , 0.39215687, 0.5019608 ],\n",
              "         [0.40784314, 0.42745098, 0.53333336]],\n",
              "\n",
              "        [[0.5411765 , 0.59607846, 0.64705884],\n",
              "         [0.50980395, 0.5647059 , 0.6156863 ],\n",
              "         [0.4745098 , 0.53333336, 0.5803922 ],\n",
              "         ...,\n",
              "         [0.3647059 , 0.3882353 , 0.5019608 ],\n",
              "         [0.39607844, 0.41960785, 0.5254902 ],\n",
              "         [0.4392157 , 0.4627451 , 0.5647059 ]],\n",
              "\n",
              "        [[0.5137255 , 0.5686275 , 0.61960787],\n",
              "         [0.47843137, 0.53333336, 0.58431375],\n",
              "         [0.43529412, 0.49411765, 0.54509807],\n",
              "         ...,\n",
              "         [0.39607844, 0.42352942, 0.5294118 ],\n",
              "         [0.43529412, 0.4627451 , 0.5647059 ],\n",
              "         [0.48235294, 0.50980395, 0.6117647 ]]],\n",
              "\n",
              "\n",
              "       [[[0.5882353 , 0.627451  , 0.6627451 ],\n",
              "         [0.5882353 , 0.6392157 , 0.6666667 ],\n",
              "         [0.59607846, 0.65882355, 0.6745098 ],\n",
              "         ...,\n",
              "         [0.6       , 0.6745098 , 0.7058824 ],\n",
              "         [0.5882353 , 0.67058825, 0.70980394],\n",
              "         [0.5764706 , 0.6627451 , 0.7058824 ]],\n",
              "\n",
              "        [[0.5882353 , 0.627451  , 0.6627451 ],\n",
              "         [0.5921569 , 0.6392157 , 0.6627451 ],\n",
              "         [0.6       , 0.65882355, 0.67058825],\n",
              "         ...,\n",
              "         [0.6117647 , 0.68235296, 0.7058824 ],\n",
              "         [0.6       , 0.67058825, 0.7058824 ],\n",
              "         [0.5882353 , 0.6627451 , 0.7019608 ]],\n",
              "\n",
              "        [[0.5647059 , 0.6039216 , 0.6392157 ],\n",
              "         [0.57254905, 0.6156863 , 0.6392157 ],\n",
              "         [0.5803922 , 0.63529414, 0.64705884],\n",
              "         ...,\n",
              "         [0.6156863 , 0.6745098 , 0.69411767],\n",
              "         [0.6       , 0.65882355, 0.6862745 ],\n",
              "         [0.5882353 , 0.64705884, 0.6784314 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.5294118 , 0.5882353 , 0.654902  ],\n",
              "         [0.5254902 , 0.58431375, 0.6509804 ],\n",
              "         [0.5176471 , 0.5764706 , 0.64705884],\n",
              "         ...,\n",
              "         [0.4862745 , 0.54901963, 0.6156863 ],\n",
              "         [0.47843137, 0.54509807, 0.6156863 ],\n",
              "         [0.4745098 , 0.5411765 , 0.61960787]],\n",
              "\n",
              "        [[0.5764706 , 0.64705884, 0.7019608 ],\n",
              "         [0.5764706 , 0.6431373 , 0.7019608 ],\n",
              "         [0.5764706 , 0.6431373 , 0.7019608 ],\n",
              "         ...,\n",
              "         [0.54509807, 0.60784316, 0.6666667 ],\n",
              "         [0.54509807, 0.60784316, 0.6666667 ],\n",
              "         [0.5411765 , 0.60784316, 0.67058825]],\n",
              "\n",
              "        [[0.62352943, 0.69411767, 0.7411765 ],\n",
              "         [0.62352943, 0.69411767, 0.74509805],\n",
              "         [0.62352943, 0.69411767, 0.7490196 ],\n",
              "         ...,\n",
              "         [0.59607846, 0.65882355, 0.70980394],\n",
              "         [0.59607846, 0.65882355, 0.7137255 ],\n",
              "         [0.59607846, 0.65882355, 0.7176471 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.26666668, 0.21176471, 0.2       ],\n",
              "         [0.27058825, 0.21568628, 0.20392157],\n",
              "         [0.28235295, 0.22745098, 0.21568628],\n",
              "         ...,\n",
              "         [0.45882353, 0.41568628, 0.4       ],\n",
              "         [0.45882353, 0.41568628, 0.39607844],\n",
              "         [0.45882353, 0.41568628, 0.39215687]],\n",
              "\n",
              "        [[0.28235295, 0.22745098, 0.21568628],\n",
              "         [0.28627452, 0.23137255, 0.21960784],\n",
              "         [0.29803923, 0.24313726, 0.23137255],\n",
              "         ...,\n",
              "         [0.45882353, 0.41568628, 0.4       ],\n",
              "         [0.45882353, 0.41568628, 0.39607844],\n",
              "         [0.45882353, 0.41568628, 0.39607844]],\n",
              "\n",
              "        [[0.30980393, 0.25490198, 0.24313726],\n",
              "         [0.3137255 , 0.25882354, 0.24705882],\n",
              "         [0.33333334, 0.2784314 , 0.26666668],\n",
              "         ...,\n",
              "         [0.45882353, 0.41568628, 0.4       ],\n",
              "         [0.45882353, 0.41568628, 0.4       ],\n",
              "         [0.45882353, 0.41568628, 0.4       ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         ...,\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ]],\n",
              "\n",
              "        [[0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         ...,\n",
              "         [0.4627451 , 0.41568628, 0.36862746],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ]],\n",
              "\n",
              "        [[0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         [0.47058824, 0.43529412, 0.4       ],\n",
              "         ...,\n",
              "         [0.4627451 , 0.41568628, 0.36862746],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ],\n",
              "         [0.45882353, 0.4117647 , 0.3647059 ]]],\n",
              "\n",
              "\n",
              "       [[[0.3764706 , 0.36078432, 0.3254902 ],\n",
              "         [0.37254903, 0.3529412 , 0.33333334],\n",
              "         [0.3647059 , 0.34509805, 0.32941177],\n",
              "         ...,\n",
              "         [0.69411767, 0.7254902 , 0.7372549 ],\n",
              "         [0.69411767, 0.7254902 , 0.73333335],\n",
              "         [0.6901961 , 0.72156864, 0.7294118 ]],\n",
              "\n",
              "        [[0.37254903, 0.35686275, 0.31764707],\n",
              "         [0.36862746, 0.34901962, 0.3254902 ],\n",
              "         [0.35686275, 0.3372549 , 0.3254902 ],\n",
              "         ...,\n",
              "         [0.69803923, 0.7372549 , 0.74509805],\n",
              "         [0.7058824 , 0.7411765 , 0.7490196 ],\n",
              "         [0.70980394, 0.7411765 , 0.7490196 ]],\n",
              "\n",
              "        [[0.36862746, 0.3529412 , 0.32156864],\n",
              "         [0.36862746, 0.34901962, 0.32941177],\n",
              "         [0.36078432, 0.34117648, 0.3254902 ],\n",
              "         ...,\n",
              "         [0.69803923, 0.7372549 , 0.74509805],\n",
              "         [0.6901961 , 0.7254902 , 0.73333335],\n",
              "         [0.6901961 , 0.72156864, 0.73333335]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40784314, 0.39607844, 0.37254903],\n",
              "         [0.40392157, 0.3882353 , 0.3764706 ],\n",
              "         [0.4       , 0.38431373, 0.3764706 ],\n",
              "         ...,\n",
              "         [0.6862745 , 0.7490196 , 0.7490196 ],\n",
              "         [0.6431373 , 0.69411767, 0.7058824 ],\n",
              "         [0.6117647 , 0.64705884, 0.6784314 ]],\n",
              "\n",
              "        [[0.40784314, 0.39607844, 0.36862746],\n",
              "         [0.40392157, 0.3882353 , 0.37254903],\n",
              "         [0.4       , 0.38039216, 0.37254903],\n",
              "         ...,\n",
              "         [0.7176471 , 0.77254903, 0.77254903],\n",
              "         [0.69411767, 0.7411765 , 0.7490196 ],\n",
              "         [0.68235296, 0.7176471 , 0.7411765 ]],\n",
              "\n",
              "        [[0.40784314, 0.39607844, 0.36862746],\n",
              "         [0.40392157, 0.3882353 , 0.37254903],\n",
              "         [0.4       , 0.38039216, 0.37254903],\n",
              "         ...,\n",
              "         [0.7294118 , 0.78039217, 0.78039217],\n",
              "         [0.7254902 , 0.76862746, 0.77254903],\n",
              "         [0.7294118 , 0.7607843 , 0.77254903]]],\n",
              "\n",
              "\n",
              "       [[[0.7137255 , 0.7490196 , 0.7294118 ],\n",
              "         [0.69411767, 0.7294118 , 0.70980394],\n",
              "         [0.65882355, 0.6901961 , 0.6745098 ],\n",
              "         ...,\n",
              "         [0.4392157 , 0.45490196, 0.44313726],\n",
              "         [0.44705883, 0.44705883, 0.43529412],\n",
              "         [0.44705883, 0.44313726, 0.42745098]],\n",
              "\n",
              "        [[0.7254902 , 0.7647059 , 0.7411765 ],\n",
              "         [0.69411767, 0.73333335, 0.7137255 ],\n",
              "         [0.6392157 , 0.67058825, 0.65882355],\n",
              "         ...,\n",
              "         [0.42745098, 0.44705883, 0.4392157 ],\n",
              "         [0.4392157 , 0.44313726, 0.43529412],\n",
              "         [0.44313726, 0.4392157 , 0.43137255]],\n",
              "\n",
              "        [[0.72156864, 0.7647059 , 0.7490196 ],\n",
              "         [0.6784314 , 0.7176471 , 0.7058824 ],\n",
              "         [0.6       , 0.6313726 , 0.627451  ],\n",
              "         ...,\n",
              "         [0.40392157, 0.42352942, 0.42745098],\n",
              "         [0.43137255, 0.4392157 , 0.4392157 ],\n",
              "         [0.43529412, 0.43529412, 0.42745098]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.75686276, 0.7921569 , 0.8       ],\n",
              "         [0.7490196 , 0.7882353 , 0.79607844],\n",
              "         [0.7254902 , 0.7647059 , 0.77254903],\n",
              "         ...,\n",
              "         [0.43137255, 0.4392157 , 0.41960785],\n",
              "         [0.45490196, 0.45490196, 0.43529412],\n",
              "         [0.45490196, 0.4509804 , 0.43137255]],\n",
              "\n",
              "        [[0.7607843 , 0.7882353 , 0.7921569 ],\n",
              "         [0.75686276, 0.78431374, 0.7882353 ],\n",
              "         [0.7372549 , 0.76862746, 0.77254903],\n",
              "         ...,\n",
              "         [0.43137255, 0.4392157 , 0.4117647 ],\n",
              "         [0.4509804 , 0.45490196, 0.42745098],\n",
              "         [0.45490196, 0.4509804 , 0.42745098]],\n",
              "\n",
              "        [[0.75686276, 0.78039217, 0.78039217],\n",
              "         [0.74509805, 0.76862746, 0.76862746],\n",
              "         [0.72156864, 0.7529412 , 0.7490196 ],\n",
              "         ...,\n",
              "         [0.4392157 , 0.4392157 , 0.4117647 ],\n",
              "         [0.45490196, 0.45490196, 0.42352942],\n",
              "         [0.4509804 , 0.4509804 , 0.41960785]]]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed Images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[0.25624526, 0.24670409, 0.23406743],\n",
              "         [0.2566257 , 0.24333379, 0.2317806 ],\n",
              "         [0.24792342, 0.23554192, 0.22855999],\n",
              "         ...,\n",
              "         [0.21654642, 0.21048959, 0.20684105],\n",
              "         [0.21729618, 0.20684811, 0.2057529 ],\n",
              "         [0.2206265 , 0.21105129, 0.20664234]],\n",
              "\n",
              "        [[0.2624044 , 0.24970174, 0.23464307],\n",
              "         [0.26788363, 0.25029662, 0.23456906],\n",
              "         [0.259685  , 0.24414706, 0.23278598],\n",
              "         ...,\n",
              "         [0.22019504, 0.21104442, 0.2016129 ],\n",
              "         [0.22241661, 0.21037734, 0.20302267],\n",
              "         [0.22305025, 0.21228851, 0.21145692]],\n",
              "\n",
              "        [[0.26430038, 0.25237852, 0.24801461],\n",
              "         [0.2653948 , 0.25079352, 0.2378017 ],\n",
              "         [0.2620103 , 0.24952039, 0.24180552],\n",
              "         ...,\n",
              "         [0.22342777, 0.21523482, 0.21021926],\n",
              "         [0.22636293, 0.21693102, 0.20899604],\n",
              "         [0.2296463 , 0.21627414, 0.21128888]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.28288665, 0.27343488, 0.26983193],\n",
              "         [0.2833251 , 0.27585918, 0.26953492],\n",
              "         [0.2754167 , 0.2690996 , 0.26430508],\n",
              "         ...,\n",
              "         [0.24659437, 0.23821917, 0.23308453],\n",
              "         [0.25590375, 0.23940337, 0.2308621 ],\n",
              "         [0.24518782, 0.23802574, 0.22948581]],\n",
              "\n",
              "        [[0.27901578, 0.26611257, 0.26378614],\n",
              "         [0.27489063, 0.26750576, 0.263937  ],\n",
              "         [0.27039704, 0.26317677, 0.262629  ],\n",
              "         ...,\n",
              "         [0.25323522, 0.2399671 , 0.2317798 ],\n",
              "         [0.2508663 , 0.23583053, 0.22819044],\n",
              "         [0.24302311, 0.23140794, 0.23006944]],\n",
              "\n",
              "        [[0.28081816, 0.2670603 , 0.2607094 ],\n",
              "         [0.27232566, 0.2627386 , 0.2576971 ],\n",
              "         [0.26479745, 0.2558624 , 0.25512114],\n",
              "         ...,\n",
              "         [0.24521676, 0.23240425, 0.22742116],\n",
              "         [0.24657196, 0.23301132, 0.22555304],\n",
              "         [0.24667233, 0.23419347, 0.22708188]]],\n",
              "\n",
              "\n",
              "       [[[0.686737  , 0.6985233 , 0.71454877],\n",
              "         [0.69419456, 0.70445865, 0.71637046],\n",
              "         [0.6961137 , 0.7090424 , 0.7245739 ],\n",
              "         ...,\n",
              "         [0.62502533, 0.6354446 , 0.6512327 ],\n",
              "         [0.62395555, 0.62817985, 0.64642143],\n",
              "         [0.6276544 , 0.63075376, 0.6476136 ]],\n",
              "\n",
              "        [[0.68228966, 0.6947973 , 0.7104681 ],\n",
              "         [0.6904784 , 0.7025734 , 0.7176682 ],\n",
              "         [0.69145095, 0.70740324, 0.7232809 ],\n",
              "         ...,\n",
              "         [0.61875474, 0.62659866, 0.6476742 ],\n",
              "         [0.6137415 , 0.61716187, 0.64022523],\n",
              "         [0.61201787, 0.6155082 , 0.63960814]],\n",
              "\n",
              "        [[0.67135304, 0.6843901 , 0.7051729 ],\n",
              "         [0.679583  , 0.6940574 , 0.71178293],\n",
              "         [0.6803518 , 0.6966031 , 0.71577156],\n",
              "         ...,\n",
              "         [0.60538924, 0.612739  , 0.63797545],\n",
              "         [0.59906536, 0.6030653 , 0.6271874 ],\n",
              "         [0.5994114 , 0.60343385, 0.6319595 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.6641563 , 0.6757809 , 0.69415575],\n",
              "         [0.6700741 , 0.68273365, 0.698952  ],\n",
              "         [0.67063034, 0.6860885 , 0.70433295],\n",
              "         ...,\n",
              "         [0.595315  , 0.60479844, 0.62714034],\n",
              "         [0.5838225 , 0.59347326, 0.6189307 ],\n",
              "         [0.58142227, 0.5898033 , 0.61510605]],\n",
              "\n",
              "        [[0.67079794, 0.6826607 , 0.7004142 ],\n",
              "         [0.67643714, 0.686759  , 0.7009711 ],\n",
              "         [0.6793727 , 0.69244325, 0.7089285 ],\n",
              "         ...,\n",
              "         [0.61160415, 0.6220632 , 0.64129096],\n",
              "         [0.6023941 , 0.61122   , 0.63265944],\n",
              "         [0.5944437 , 0.6021156 , 0.62282056]],\n",
              "\n",
              "        [[0.6693558 , 0.6841727 , 0.7011174 ],\n",
              "         [0.6729129 , 0.68414164, 0.7004842 ],\n",
              "         [0.6746112 , 0.68675524, 0.7055291 ],\n",
              "         ...,\n",
              "         [0.62263584, 0.63301384, 0.6504056 ],\n",
              "         [0.6110581 , 0.6181798 , 0.6348828 ],\n",
              "         [0.6001267 , 0.60937095, 0.62844956]]],\n",
              "\n",
              "\n",
              "       [[[0.661516  , 0.6700545 , 0.684358  ],\n",
              "         [0.6703388 , 0.6782219 , 0.6877656 ],\n",
              "         [0.6719575 , 0.6832118 , 0.6959097 ],\n",
              "         ...,\n",
              "         [0.58720905, 0.59477895, 0.60784537],\n",
              "         [0.58180165, 0.58403885, 0.60164213],\n",
              "         [0.5831049 , 0.5830873 , 0.6013131 ]],\n",
              "\n",
              "        [[0.6568265 , 0.66731113, 0.67982894],\n",
              "         [0.66402435, 0.67446846, 0.6856814 ],\n",
              "         [0.66570807, 0.6809411 , 0.6943397 ],\n",
              "         ...,\n",
              "         [0.58000886, 0.58625144, 0.60632306],\n",
              "         [0.5706189 , 0.5726864 , 0.59646666],\n",
              "         [0.5656288 , 0.5669488 , 0.58973145]],\n",
              "\n",
              "        [[0.64339024, 0.6561756 , 0.6750575 ],\n",
              "         [0.6510635 , 0.66529197, 0.6808361 ],\n",
              "         [0.6517757 , 0.6669487 , 0.68515   ],\n",
              "         ...,\n",
              "         [0.5645148 , 0.57021403, 0.5969795 ],\n",
              "         [0.553798  , 0.5580931 , 0.582389  ],\n",
              "         [0.5508367 , 0.554438  , 0.5826105 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.6367888 , 0.6465144 , 0.66258967],\n",
              "         [0.64437544, 0.6559895 , 0.67090935],\n",
              "         [0.6458843 , 0.6604135 , 0.67617726],\n",
              "         ...,\n",
              "         [0.5542985 , 0.55626726, 0.5801501 ],\n",
              "         [0.54143   , 0.5433988 , 0.5675961 ],\n",
              "         [0.53477174, 0.5377132 , 0.562219  ]],\n",
              "\n",
              "        [[0.64425224, 0.6540635 , 0.66950744],\n",
              "         [0.65064836, 0.6582948 , 0.66985065],\n",
              "         [0.653353  , 0.6644123 , 0.6785855 ],\n",
              "         ...,\n",
              "         [0.56526935, 0.57046056, 0.5935943 ],\n",
              "         [0.55693704, 0.55921453, 0.58186543],\n",
              "         [0.54760104, 0.54826885, 0.5673552 ]],\n",
              "\n",
              "        [[0.64629513, 0.6586216 , 0.6729744 ],\n",
              "         [0.64963526, 0.658261  , 0.6717845 ],\n",
              "         [0.65066916, 0.6610471 , 0.6768268 ],\n",
              "         ...,\n",
              "         [0.57559496, 0.5803487 , 0.5993266 ],\n",
              "         [0.5697247 , 0.5712877 , 0.58912665],\n",
              "         [0.55884814, 0.5635055 , 0.58167   ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.40071708, 0.3814262 , 0.36307245],\n",
              "         [0.40098816, 0.3786538 , 0.3607595 ],\n",
              "         [0.39579383, 0.37760195, 0.36308414],\n",
              "         ...,\n",
              "         [0.36579412, 0.34949186, 0.33362877],\n",
              "         [0.36748663, 0.34758666, 0.3304034 ],\n",
              "         [0.36672202, 0.3444308 , 0.32697934]],\n",
              "\n",
              "        [[0.40339947, 0.3808006 , 0.36002147],\n",
              "         [0.40523738, 0.37916175, 0.35722044],\n",
              "         [0.40322247, 0.38049516, 0.36145696],\n",
              "         ...,\n",
              "         [0.36669853, 0.34774974, 0.3276499 ],\n",
              "         [0.3655187 , 0.34400415, 0.32644415],\n",
              "         [0.36519596, 0.34264788, 0.3279343 ]],\n",
              "\n",
              "        [[0.39928466, 0.37783554, 0.36177015],\n",
              "         [0.40028352, 0.37793767, 0.35714376],\n",
              "         [0.4007066 , 0.3808928 , 0.36190683],\n",
              "         ...,\n",
              "         [0.36368555, 0.34794903, 0.33280912],\n",
              "         [0.36238098, 0.34436977, 0.32962793],\n",
              "         [0.35855383, 0.33990207, 0.3275079 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40256548, 0.38659275, 0.3731649 ],\n",
              "         [0.39986858, 0.38421544, 0.3687165 ],\n",
              "         [0.4021858 , 0.38933945, 0.37718046],\n",
              "         ...,\n",
              "         [0.3835302 , 0.36462164, 0.34987906],\n",
              "         [0.38417107, 0.36086702, 0.34853277],\n",
              "         [0.3751613 , 0.3579613 , 0.3431906 ]],\n",
              "\n",
              "        [[0.40821072, 0.39054003, 0.37382796],\n",
              "         [0.40669894, 0.3911607 , 0.37196657],\n",
              "         [0.4064693 , 0.3915481 , 0.37791452],\n",
              "         ...,\n",
              "         [0.39689094, 0.3720714 , 0.35208887],\n",
              "         [0.38881347, 0.3659114 , 0.35096142],\n",
              "         [0.38218635, 0.3618076 , 0.34741217]],\n",
              "\n",
              "        [[0.40631852, 0.39265746, 0.37478518],\n",
              "         [0.40827352, 0.3920308 , 0.37275535],\n",
              "         [0.40676218, 0.39074203, 0.3751492 ],\n",
              "         ...,\n",
              "         [0.3950874 , 0.3703868 , 0.34941775],\n",
              "         [0.38886017, 0.3639265 , 0.34390834],\n",
              "         [0.3866437 , 0.3659324 , 0.35076863]]],\n",
              "\n",
              "\n",
              "       [[[0.28516716, 0.24996835, 0.25667647],\n",
              "         [0.28355044, 0.24500126, 0.26112202],\n",
              "         [0.2784461 , 0.25045997, 0.26951736],\n",
              "         ...,\n",
              "         [0.561023  , 0.5742422 , 0.59977853],\n",
              "         [0.56696576, 0.5743067 , 0.592153  ],\n",
              "         [0.5566759 , 0.5659652 , 0.58529747]],\n",
              "\n",
              "        [[0.2911488 , 0.2535085 , 0.25788236],\n",
              "         [0.295203  , 0.24986102, 0.26035947],\n",
              "         [0.2905708 , 0.25354636, 0.2722356 ],\n",
              "         ...,\n",
              "         [0.5650808 , 0.58042604, 0.6034567 ],\n",
              "         [0.5683654 , 0.57928085, 0.5946555 ],\n",
              "         [0.5590035 , 0.57332045, 0.5935897 ]],\n",
              "\n",
              "        [[0.2886393 , 0.26007771, 0.27167794],\n",
              "         [0.29106623, 0.25548768, 0.27270728],\n",
              "         [0.28960374, 0.25869644, 0.2764014 ],\n",
              "         ...,\n",
              "         [0.5496183 , 0.56931067, 0.5952549 ],\n",
              "         [0.55694157, 0.5739324 , 0.59428096],\n",
              "         [0.5505928 , 0.5649423 , 0.58443964]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.28965598, 0.26206505, 0.27345017],\n",
              "         [0.29350007, 0.26239341, 0.27176383],\n",
              "         [0.2895607 , 0.26105282, 0.27222478],\n",
              "         ...,\n",
              "         [0.5345218 , 0.5494834 , 0.57316494],\n",
              "         [0.5364489 , 0.54842436, 0.5700513 ],\n",
              "         [0.53098553, 0.54470086, 0.5687346 ]],\n",
              "\n",
              "        [[0.28747314, 0.25685513, 0.26785222],\n",
              "         [0.29014722, 0.25594965, 0.26436582],\n",
              "         [0.2888211 , 0.25957707, 0.27458787],\n",
              "         ...,\n",
              "         [0.5397093 , 0.5552453 , 0.57114804],\n",
              "         [0.5397893 , 0.55208683, 0.5686689 ],\n",
              "         [0.54502916, 0.5522474 , 0.5692927 ]],\n",
              "\n",
              "        [[0.2819328 , 0.25642514, 0.26392138],\n",
              "         [0.28640726, 0.25637028, 0.264078  ],\n",
              "         [0.2819875 , 0.25555438, 0.2677309 ],\n",
              "         ...,\n",
              "         [0.542698  , 0.5548827 , 0.5696804 ],\n",
              "         [0.5432383 , 0.5517586 , 0.56811714],\n",
              "         [0.54228556, 0.5511387 , 0.56649464]]],\n",
              "\n",
              "\n",
              "       [[[0.5246592 , 0.53579545, 0.5754899 ],\n",
              "         [0.5279517 , 0.53913516, 0.5796419 ],\n",
              "         [0.5225144 , 0.54070884, 0.58873045],\n",
              "         ...,\n",
              "         [0.41424647, 0.41571015, 0.46733505],\n",
              "         [0.41679353, 0.42002204, 0.46876863],\n",
              "         [0.42483488, 0.42666793, 0.4737994 ]],\n",
              "\n",
              "        [[0.5288186 , 0.54001087, 0.5803706 ],\n",
              "         [0.53483564, 0.54537666, 0.58655924],\n",
              "         [0.53315556, 0.5510443 , 0.59845793],\n",
              "         ...,\n",
              "         [0.4176783 , 0.42173856, 0.47102696],\n",
              "         [0.42309317, 0.4271209 , 0.48106945],\n",
              "         [0.42687896, 0.42837867, 0.47683993]],\n",
              "\n",
              "        [[0.541376  , 0.5560981 , 0.5929583 ],\n",
              "         [0.53907967, 0.55530787, 0.5979797 ],\n",
              "         [0.53810626, 0.55834705, 0.60674775],\n",
              "         ...,\n",
              "         [0.42488188, 0.43295676, 0.4900592 ],\n",
              "         [0.42992884, 0.43874887, 0.49572635],\n",
              "         [0.42958283, 0.43843246, 0.48978427]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.53053993, 0.5482168 , 0.5978067 ],\n",
              "         [0.5324868 , 0.54984176, 0.59690773],\n",
              "         [0.52773273, 0.5481652 , 0.5980305 ],\n",
              "         ...,\n",
              "         [0.42811507, 0.43652594, 0.49716407],\n",
              "         [0.4453871 , 0.4554218 , 0.50645244],\n",
              "         [0.45736888, 0.46759522, 0.5087312 ]],\n",
              "\n",
              "        [[0.51794523, 0.5354251 , 0.58190644],\n",
              "         [0.51891613, 0.53566325, 0.58078617],\n",
              "         [0.51477045, 0.5342712 , 0.5834141 ],\n",
              "         ...,\n",
              "         [0.42149353, 0.4223484 , 0.47657073],\n",
              "         [0.44095132, 0.44471762, 0.497035  ],\n",
              "         [0.44177026, 0.4490421 , 0.49227604]],\n",
              "\n",
              "        [[0.5165804 , 0.53358483, 0.5779536 ],\n",
              "         [0.510732  , 0.52895594, 0.5772479 ],\n",
              "         [0.50621843, 0.52220404, 0.5711948 ],\n",
              "         ...,\n",
              "         [0.4008137 , 0.4056457 , 0.45751464],\n",
              "         [0.41844028, 0.42112195, 0.46748057],\n",
              "         [0.42511797, 0.43367517, 0.475354  ]]]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "[[ 1.1470003   0.03083169]\n",
            " [-1.0362449  -0.5714018 ]\n",
            " [-0.62678015  0.44953865]\n",
            " [-0.9419123  -0.9014176 ]\n",
            " [-1.1341393  -0.30691433]\n",
            " [ 0.15119319  0.31691745]\n",
            " [ 2.787236   -2.2797241 ]\n",
            " [ 0.9722995  -2.0603397 ]\n",
            " [-1.0128984   0.7717497 ]\n",
            " [-0.56672204  0.19338746]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "K5pNnBMf71LL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_width, grid_height = (4, 2)\n",
        "\n",
        "random = np.random.choice(x_test.shape[0], 6, replace=False)\n",
        "real = x_test[random]\n",
        "z_mean,z_log_var,z = encoder.predict(real)\n",
        "reconstructed_img = decoder.predict(z)\n",
        "\n",
        "fig, axes = plt.subplots(2, 6, figsize=(15, 5))\n",
        "\n",
        "for i in range(6):\n",
        "    axes[0, i].imshow(real[i, :, :, 0], cmap=\"Greys\")\n",
        "    axes[0, i].axis(\"off\")\n",
        "    axes[0, i].set_title(\"real\")\n",
        "\n",
        "for i in range(6):\n",
        "    axes[1, i].imshow(reconstructed_img[i, :, :, 0], cmap=\"Greys\")\n",
        "    axes[1, i].axis(\"off\")\n",
        "    axes[1, i].set_title(\"reconstructed\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "GQAZGzLcIeeg",
        "outputId": "fdf3816c-ae47-45ee-d8c4-cc0e06e6a331"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discussion\n",
        "\n",
        "Model Overall Grade (50 epoch; Batch 128):B-\n",
        "\n",
        "Clarity:\n",
        "\n",
        "With a setting of batch size 128 and epochs of 50 the clarity of the reconstructed image is mediocre, I think with further training, and feeding the data through the VAE’s more will enhance the clarity will decrease the loss values obtained through training. The clarity on the real is much better then the reconstructed\n",
        "\n",
        "Distortion:\n",
        "\n",
        "There is a level of distortion to the reconstructed images. There is a high level of loss in the training process at each dimension which might indicate the need to alter the model's structure. Overall, there are losses in detail and reconfiguration is at hand.\n",
        "\n",
        "Variability:\n",
        "\n",
        "The images show low variability as the results are pretty uniform in their shortcomings. They all display a level of blur as well as the same thickness of the digits. However, we may want to point out the difference in performance for different colors. For the images with darker backgrounds, it is a bit harder to make out what the digits are, and the blur seems to be enhanced.\n",
        "\n",
        "Generalization:\n",
        "\n",
        "From the outputs my VAE has grasped the general distribution of the data. It handles unseen images well, resembling the training data."
      ],
      "metadata": {
        "id": "Br4QHF7R9BEo"
      }
    }
  ]
}